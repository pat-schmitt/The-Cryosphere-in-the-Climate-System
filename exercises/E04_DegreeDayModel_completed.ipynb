{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson: degree day model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Today we are going to play around a bit with the [degree day model](http://www.antarcticglaciers.org/glaciers-and-climate/numerical-ice-sheet-models/modelling-glacier-melt/) (DDM) to understand it a bit better and to learn a little bit more about logical tools in numpy/pandas.\n",
    "\n",
    "\n",
    "**Spend some time to read the webpage linked above explaining how the simple degree day model works.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the AWS data at Zhadang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports and defaults\n",
    "import pandas as pd  \n",
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "pd.options.display.max_rows = 14\n",
    "import seaborn as sns\n",
    "sns.set_style('ticks')\n",
    "sns.set_context('talk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the data\n",
    "df = pd.read_csv('data/data_Zhadang_localtime.csv', index_col=0, parse_dates=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Such 'temperature index' approaches can really be applied, hourly, daily, monthly or whatever, though in cryopsheric science the daily timescale is most widely used. So we resample accordingly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resample \n",
    "df = df.resample('D').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test the model, we are concentrating on the melting season 2012, which we will define as starting in the middle of May based on the data we plotted in the previous exercise, and running to the end of the available data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc['2012-05-15':]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How can we check if ablation is happening? Well, we can check that the surface is lowering during this period ...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['SR50'].plot(title='Surface height in m (0 = ice)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Simplest DDM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the simplest DDM, we are going to use a single factor for the entire melting period. The DDM formulation is very simple:\n",
    "\n",
    "$$Melt = f \\cdot PDD$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where PDD is the sum total of daily average temperatures above 0°C in a given time period and $f$ is a melting factor. Let's define the melt in meters of snow/ice which is melted away. Determine the unit that $f$ should have in that (quite clumsy) case.\n",
    "\n",
    "OK, so now we need to count the PDD's over that period. One method that you already learned is following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select all days with mean temperature above 0\n",
    "seltemp = df.TEMP.loc[df.TEMP > 0]\n",
    "# sum these daily mean temperatures\n",
    "seltemp.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the purpose of our modelling, however, it is easier to define a new variable (PDD), which is the daily average of temperature when it is above 0°C, and zero otherwise. For this we are using the numpy function [np.where](http://docs.scipy.org/doc/numpy-1.10.1/reference/generated/numpy.where.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['PDD'] = np.where(df.TEMP > 0, df.TEMP, 0)\n",
    "# print this if you want to look at the values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify that the the sum of this new PDD variable corresponds to our computation above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# by summing it we can verify that its the same as the answer above\n",
    "df.PDD.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bearing in mind that our defined melt season is only 3.5 months long, this number seems quite high ... so either there are loads of positive mean temperatures, or there are some 'heatwave' days ...\n",
    "To find out which we can do the following to find out what percentage of the ablation season data is above 0°C:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seltemp.size / df.TEMP.size * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q: Are you surprised by the percentage of days of that experience melt?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to calibrate our model, i.e. compute our factor $f$. \n",
    "\n",
    "The data we have is actually lowering not melt, so we need the total of snow/ice lowering (in m) during this period. WE can find this using  `iloc[]` (if you dont know this look it up or ask the notebook what it does) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_melt = df.SR50.iloc[-1] - df.SR50.iloc[0]  \n",
    "# index location [0 to (length)-1] allowing us to subtract the fist from the last value\n",
    "obs_melt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Its worth noting that in most glaciological applications this ablation would be expressed differently e.g. as lowering in units of water equivalent (e.g. mm w.e.) \n",
    "\n",
    "\n",
    "Using the formula $$Melt = f \\cdot PDD$$ we can calculate our melt factor as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so looking at the formula above ...\n",
    "melt_factor = obs_melt / df['PDD'].sum()\n",
    "melt_factor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is now very easy to define a variable (MELT1), which is the daily melt due to this factor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['MELT1'] = df['PDD'] * melt_factor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q: Lets plot this new variable. What are we looking at?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot it here and label the y-axis correctly\n",
    "\n",
    "df['MELT1'].plot();\n",
    "plt.ylabel('modelled lowering [m/day]');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to compare our modelled melt with observations, its more useful for us to show the modelled melt as a cumulative sum so that we can compare it to the sonic range data available for the station: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['MELT1'] = (df['PDD'] * melt_factor).cumsum()\n",
    "df['MELT1'].plot();\n",
    "plt.ylabel('cumulative modelled lowering [m/day]');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this plot now starts at 0, but we know that 0 reference in the sonic ranger data is the ice surface and at the start of the ablation season the surface was snow above this. \n",
    "\n",
    "Therefore, we now add the starting snow depth to this timeseries. We select the first element of the observations array with `iloc[]` and add it to ours:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['MELT1'] = (df['PDD'] * melt_factor).cumsum() + df.SR50.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done! \n",
    "\n",
    "**Q: So how well does out model do? Let's plot the result of our modeling approach with the sonic ranger (SR50) data to see:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot both series in one plot to compare them\n",
    "\n",
    "df[['MELT1', 'SR50']].plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q: Discuss the performance of our model. Where is it performing well? Where is it performing less well? Can you tell why?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so consider the slopes of the curves\n",
    "# up until the third week of June the model does not match too well, nor in the last 2 weeks of August\n",
    "# in the middle section, although there is am offset the curves are quite well matched\n",
    "# if we look back at our plot of the surface height, we know:\n",
    "# there was snow (i) at the beginning, and (ii) probably small snow events at the end of the record ...\n",
    "# OR ... the surface height changes at the end could be related to tilting of the AWS?\n",
    "# note that the way this model is calibrated means that the final surface height *will* match\n",
    "# note that we are evaluating with your turning data which is bad!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. A more reasonable DDM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is more reasonable to distinguish between snow and ice in our model. Fortunately, the person who provided the data nicely set the 0 level to the original ice surface before the ablation season."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q: To identify the snow that is removed during the first part of the ablation season, lets use the `np.where()` function to add a new variable IS_SNOW to the dataframe, which is equal to True when the surface is above 0 and to False otherwise.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here\n",
    "\n",
    "df['IS_SNOW'] = np.where(df.SR50 > 0, True, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q: Now follow the recipe from the simple example above to compute the PDD and melt factor $f$ for the snowmelt period at the start of the ablation season:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, compute the PDD sum during the snowmelt period:\n",
    "# then, compute the observed melt during this period:\n",
    "# finally, compute the factor:\n",
    "\n",
    "\n",
    "# first, compute the PDD sum during the snowmelt period:\n",
    "pdd_snow = df.PDD.loc[df['IS_SNOW']].sum()\n",
    "# then, compute the observed melt during this period:\n",
    "melt_snow = - df.SR50.iloc[0]\n",
    "# finally, compute the factor:\n",
    "fac_snow = melt_snow / pdd_snow\n",
    "fac_snow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To isolate the period when the ice is exposed we can look for when there is NOT snow by using the operator, \"~\", which is the logical operator for \"not\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can see the behavior by doing this:\n",
    "print(np.array([True, False, True]))\n",
    "print(~ np.array([True, False, True]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q: Now,use this and repeat what you did for the snow covered period but for the ice covered period to get the PDD sum  and $f$ during the ice period:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, compute the PDD sum during the ice melt period:\n",
    "# then, compute the observed melt during this period. \n",
    "# Finally, compute the factor:\n",
    "\n",
    "\n",
    "# first, compute the PDD sum during the ice melt period:\n",
    "pdd_ice = df.PDD.loc[~ df['IS_SNOW']].sum()  # note the ~\n",
    "# then, compute the observed melt during this period. \n",
    "melt_ice = df.SR50.iloc[-1]\n",
    "# Finally, compute the factor:\n",
    "fac_ice = melt_ice / pdd_ice\n",
    "fac_ice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q: compare the two factors. Discuss their relative value in light of the physical properties of snow and ice. Does it make sense for you?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so what do we see?\n",
    "# for each PDD the lowering of the snow surface is 3 times as much as the ice surface\n",
    "# would you expect that?\n",
    "# remember that we are dealing with the rate of surface lowering of 2 different things: snow and ice\n",
    "# the density of ice is ~900kg/m3, but snow is less dense (even old snow)\n",
    "# so we might expect the lowering rate to be more per unit of our temperature index\n",
    "\n",
    "# but what if our calculations were based on ablation in terms of water equivalents or mass instead of surface lowering?\n",
    "# then the higher reflectance of snow might mean the melt factor for snow is smaller than for ice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q: Define a new variable (MIXED_FAC) in the dataframe, which is equal to fac_snow during the snow period and to fac_ice otherwise. Using the same approach as before, compute a new variable MELT2 wich is the cumulative melt during that period. Plot it together with the SR50 observations.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here\n",
    "\n",
    "df['MIXED_FAC'] = np.where(df['IS_SNOW'], fac_snow, fac_ice)\n",
    "df['MELT2'] = (df['PDD'] * df['MIXED_FAC']).cumsum() + df.SR50.iloc[0]\n",
    "df[['MELT1', 'MELT2', 'SR50']].plot(figsize=(10,5));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q: Discuss the performance of our new model. Is it performing better than before? Can you tell why?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ok so we have improved it, right?\n",
    "# but we have not corrected for the snow at the end of our 'ablation' season\n",
    "# remember these positive changes could be associated with tilting, but if not ...\n",
    "# then it actually means the ablation season finished earlier than we thought"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q: The lowest surface height is the 16th August instead of 1st September, how does redefining the ablation season affect our model performance?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce dataframe to the true ablation season\n",
    "df = df.loc['2012-05-15' :'2012-08-16']\n",
    "#  .... and repeat the whole exercise:\n",
    "\n",
    "# first, compute the PDD sum during the snowmelt period:\n",
    "pdd_snow = df.PDD.loc[df['IS_SNOW']].sum()\n",
    "# then, compute the observed melt during this period:\n",
    "melt_snow = - df.SR50.iloc[0]\n",
    "# finally, compute the factor:\n",
    "fac_snow = melt_snow / pdd_snow\n",
    "print(fac_snow)\n",
    "# first, compute the PDD sum during the ice melt period:\n",
    "pdd_ice = df.PDD.loc[~ df['IS_SNOW']].sum()  # note the ~\n",
    "# then, compute the observed melt during this period. \n",
    "melt_ice = df.SR50.iloc[-1]\n",
    "# Finally, compute the factor:\n",
    "fac_ice = melt_ice / pdd_ice\n",
    "print(fac_ice)\n",
    "# note the change in the fac_ice value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q: Now calculate a new melt series (MELT3) and plot it alongside MELT 2 and the sonic ranger data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a second version of MIXED_FAC for this new timeframe\n",
    "# make a cumulative timeseries of modelled melt\n",
    "# plot it alongside MELT2 and SR50\n",
    "\n",
    "df['MIXED_FAC2'] = np.where(df['IS_SNOW'], fac_snow, fac_ice)\n",
    "df['MELT3'] = (df['PDD'] * df['MIXED_FAC2']).cumsum() + df.SR50.iloc[0]\n",
    "df[['MELT1', 'MELT2', 'MELT3', 'SR50']].plot(figsize=(10,5));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a good example of how more perfect information can result in a better performance for this type of empirically fitted model.\n",
    "\n",
    "**Q: Discuss the following issues in the light of what you did in this exercise:**\n",
    "\n",
    "- Do we know if these factors are 'right'? \n",
    "- Do you expect them to work perfectly in 2013, or any other year, or on another part of the glacier?\n",
    "- Is it reasonable to expect a melt factor to stay the same over the melt season?\n",
    "- What else have we not accounted for?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. An even more reasonable DDM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our previous models, we compeletely neglected snowfall, which of course is bad. If you are ambitious, you can try to propose solutions to this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
